data:
  name: aishellorg
  vocab: egs/aishellorg/data/train_chars.txt
  batch_size: 14
  text: text
  train: egs/aishellorg/data/train
  dev: egs/aishellorg/data/dev
  finetunetrain: egs/aishellorg/data/finetunetrain
  finetunedev: egs/aishellorg/data/finetunedev
  short_first: False
  num_mel_bins: 40
  apply_cmvn: False
  normalization: True
  spec_augment: True
  left_frames: 0
  right_frames: 0
  skip_frames: 0
  from_kaldi: False
  num_works: 4
model:
  # network architecture
  type: transformer
  d_model: 320
  #输入向量维度d_model
  normalize_before: False
  concat_after: False
  # dropout
  pos_dropout_rate: 0.0
  ffn_dropout_rate: 0.0
  slf_attn_dropout_rate: 0.0
  src_attn_dropout_rate: 0.0
  residual_dropout_rate: 0.1
  # encoder related
  feat_dim: 40
  #特征维度 input 40维,通过卷积之类的层整成d_model维度
  num_enc_blocks: 6
  enc_ffn_units: 1280
  #前向传播层的隐层
  enc_input_layer: conv2d
  # decoder related
  vocab_size: 4899
  #词典大小
  num_dec_blocks: 6
  dec_ffn_units: 1280
  # attention related
  n_heads: 4
  #attention头数　h*dv=d_model dv=dk v,k的维度
  # label smoothing
  smoothing: 0.1
  activation: glu
  #前向传播层激活函数
  share_embedding: True
  loss: RELoss
  #loss函数
train:
  scheduler: stepwise
  optimizer: adam
  warmup_steps: 12000
  shuffle: True
  lr: 1.0
  clip_grad: 5
  #最大梯度阈值（梯度截断）
  epochs: 80
  accum_steps: 1
  #梯度截断步数
  grad_noise: False
  load_model: False
  save_name: transformerchange
